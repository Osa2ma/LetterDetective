{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a56fc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "950203f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "900ae18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./data'\n",
    "\n",
    "train_data=datasets.EMNIST(root=data_path,train=True,download=False,split='letters')\n",
    "test_data=datasets.EMNIST(root=data_path,train=False,download=False,split='letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce26278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([124800, 28, 28]), torch.Size([20800, 28, 28]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape,test_data.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80666ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 7\n",
    "image, label = train_data[idx]\n",
    "letter = chr(label + 64) \n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "image_rotated = F.rotate(image,90)\n",
    "image_flipped=F.vflip(image_rotated)\n",
    "\n",
    "plt.imshow(image_flipped, cmap='gray')\n",
    "plt.title(f\"Label: {label} ({letter})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3634a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated Mean: 0.1722\n",
      "Calculated Std:  0.3309\n"
     ]
    }
   ],
   "source": [
    "raw_data=train_data.data.float() / 255.0\n",
    "mean =raw_data.mean().item()\n",
    "std=raw_data.std().item()\n",
    "\n",
    "print(f\"\\nCalculated Mean: {mean:.4f}\")\n",
    "print(f\"Calculated Std:  {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56726c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=(0.1722,)\n",
    "std=(0.3309,)\n",
    "\n",
    "train_transform=transforms.Compose([\n",
    "    lambda img: transforms.functional.rotate(img, -90),\n",
    "    lambda img: transforms.functional.hflip(img),\n",
    "    transforms.RandomAffine(degrees=15,translate=(0.1,0.1),scale=(0.9,1.1),shear=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "test_transform=transforms.Compose([\n",
    "    lambda img: transforms.functional.rotate(img, -90),\n",
    "    lambda img: transforms.functional.hflip(img),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "train_data.transform=train_transform\n",
    "test_data.transform=test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d20546c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.4967, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  0.9847,\n",
      "           0.9610,  0.0603, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.4730, -0.4967, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.4374,  0.8188,  2.3357,\n",
      "           1.8735, -0.1530, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.4848, -0.2715,  0.0722,  0.8306,  0.3803, -0.4967, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.1175,  2.3357,  0.0485,\n",
      "          -0.4256, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "           1.5062,  2.2291,  2.3357,  1.5654,  0.7358, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.4730,  0.8306,  2.2409, -0.4611,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.4848, -0.2715,  0.0840,\n",
      "           1.5062,  2.4424,  1.4113, -0.0938, -0.0938, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.3900,  1.1506,  2.0513, -0.4967,\n",
      "          -0.5204, -0.5204, -0.5204, -0.4848, -0.2715,  0.4751,  1.4943,\n",
      "           2.0987,  0.8306,  0.0722, -0.4374, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204,  0.8425,  2.3594,  0.4158,\n",
      "          -0.5204, -0.5204, -0.5204, -0.4848,  2.2172,  2.4661,  2.4069,\n",
      "           1.5299, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.4848,  1.5180,  2.3831, -0.4493,\n",
      "          -0.4611, -0.2597,  0.8306,  1.5180,  1.0084,  0.9610,  0.3921,\n",
      "          -0.4848, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.4848,  0.4158,  2.4069,  2.0513,  1.1743,\n",
      "           2.0395,  2.2409,  2.4306,  1.5773, -0.4611, -0.4730, -0.4967,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204,  0.5581,  2.0987,  2.4898,  2.2765,  1.1743,\n",
      "           2.4898,  2.4069,  1.1269, -0.1175, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204,  1.8735,  1.8735,  2.4780,  2.5017,  2.4898,\n",
      "           2.4424,  2.4898,  2.2646,  0.0603,  0.0366, -0.4611, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.0938,  2.2528,  2.4661,  2.4424,  2.4424,\n",
      "           1.1506,  2.3713,  2.4661,  1.9328,  2.2054,  0.4633, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.0938,  2.4424,  1.7195,  0.9847,  0.9847,\n",
      "          -0.5085,  0.0366,  1.3639,  2.4306,  2.4424,  1.5536, -0.4374,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.4967,  1.3521,  1.4232, -0.1293, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5085, -0.2478,  1.7906,  2.1106,  2.4543,  0.4395,\n",
      "          -0.4967, -0.4967, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5085, -0.0938,  2.2409,  0.0959, -0.5085, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.4730,  1.8972,  2.4780,\n",
      "           0.9847, -0.4730, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.2597,  1.3639,  1.4113, -0.4374, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.4730,  1.1388,  2.4424,\n",
      "           0.9847, -0.4730, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.4374,  1.4113,  2.3950, -0.2597, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  1.1388,  2.4424,\n",
      "           0.9847, -0.4730, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.2834,\n",
      "           0.6647,  2.3950,  1.9328, -0.5085, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  1.8972,  2.4780,\n",
      "           0.9847, -0.4730, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  0.9373,\n",
      "           2.2172,  1.9328,  0.1788, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.3900,  2.1106,\n",
      "           2.4898,  0.9847, -0.4730, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5085,  2.3831,\n",
      "           2.3831,  2.2528, -0.0938, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  0.3921,  2.4069,\n",
      "           2.4898,  0.9847, -0.4967, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  1.3402,\n",
      "           2.4898,  2.0513, -0.4611, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  0.8188,  2.4187,\n",
      "           2.2291,  0.3921, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5085,  0.9136,\n",
      "           2.0276,  1.2928, -0.4967, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.1412,  0.9492,\n",
      "           0.4395, -0.4374, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  0.0722,\n",
      "          -0.0701, -0.2834, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,  0.0722,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204],\n",
      "         [-0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204,\n",
      "          -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204, -0.5204]]])\n"
     ]
    }
   ],
   "source": [
    "image, label = train_data[7]\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_dataloader=DataLoader(test_data,batch_size=64,shuffle=False)\n",
    "\n",
    "print(f'Number of training samples: {len(train_data)}')\n",
    "print(f'Number of test samples: {len(test_data)}')\n",
    "print(50*'=')\n",
    "print('Train Loader: \\n')\n",
    "print(f'Number of training batches: {len(train_dataloader)}')\n",
    "\n",
    "for batch_num,(data,labels) in enumerate(train_dataloader):\n",
    "    print(f'Batch {batch_num+1}:')\n",
    "    print(f' - data shape: {data.shape}')\n",
    "    print(f' - labels shape: {labels.shape}\\n\\n')\n",
    "    break \n",
    "\n",
    "print('Test Loader: \\n')\n",
    "print(f'Number of test batches: {len(test_dataloader)}')\n",
    "for batch_num,(data,labels) in enumerate(test_dataloader):\n",
    "    print(f'Batch {batch_num+1}:')\n",
    "    print(f' - data shape: {data.shape}')\n",
    "    print(f' - labels shape: {labels.shape}\\n\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6727fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=256, out_features=26, bias=True)\n",
      ")\n",
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model=nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,26)\n",
    ")\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "print(f'Model architecture:\\n{model}')\n",
    "print(f'Loss function: {loss_function}')\n",
    "print(f'Optimizer: {optimizer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c85fca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,test_dataloader,device,verbose=True):\n",
    "    model.eval()\n",
    "    num_correct_predictions = 0\n",
    "   \n",
    "    total_predictions = 0 \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets in test_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets - 1\n",
    "            outputs = model(inputs)\n",
    "            predicted_indices = torch.argmax(outputs,dim=1)\n",
    "            correct_predictions = (predicted_indices==targets).sum().item()        \n",
    "            num_correct_predictions += correct_predictions\n",
    "            batch_size = len(targets)\n",
    "            total_predictions +=batch_size \n",
    "        accuracy_percentage = (num_correct_predictions / total_predictions) * 100\n",
    "        if verbose:\n",
    "            print((f'Test Accuracy: {accuracy_percentage:.2f}%'))\n",
    "\n",
    "    return accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3df64170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_per_class(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            labels = labels - 1\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    class_accuracies = {}\n",
    "\n",
    "    for class_idx in range(26):  \n",
    "        class_targets = [\n",
    "            t for t, p in zip(all_targets, all_predictions) if t == class_idx\n",
    "        ]\n",
    "        class_predictions = [\n",
    "            p for t, p in zip(all_targets, all_predictions) if t == class_idx\n",
    "        ]\n",
    "\n",
    "        if len(class_targets) > 0:\n",
    "            class_accuracies[chr(65 + class_idx)] = accuracy_score(\n",
    "                class_targets, class_predictions\n",
    "            )\n",
    "        else:\n",
    "            class_accuracies[chr(65 + class_idx)] = 0.0  \n",
    "\n",
    "    return class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "best_test_accuracy=0.0\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    num_correct_predictions=0\n",
    "    total_predictions=0\n",
    "\n",
    "    for batch_num,(data,labels) in enumerate(train_dataloader):\n",
    "        data,labels=data.to(device),labels.to(device)\n",
    "        labels=labels-1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(data)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "        predicted_indices=torch.argmax(outputs,dim=1)\n",
    "        num_correct_predictions+=(predicted_indices==labels).sum().item()\n",
    "        total_predictions+=len(labels)\n",
    "\n",
    "    average_loss=running_loss/len(train_dataloader)\n",
    "    train_accuracy=(num_correct_predictions/total_predictions)*100\n",
    "    test_accuracy=evaluate(model,test_dataloader,device,verbose=False)\n",
    "\n",
    "    if test_accuracy>best_test_accuracy:\n",
    "        best_test_accuracy=test_accuracy\n",
    "        torch.save(model.state_dict(),'mlp_model.pth')\n",
    "        print(f\"Epoch {epoch+1}/50 | Train Loss: {average_loss:.4f} | Train Acc: {train_accuracy:.2f}% | Test Acc: {test_accuracy:.2f}% | *saved*\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}/50 | Train Loss: {average_loss:.4f} | Train Acc: {train_accuracy:.2f}% | Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(f\"\\nBest Test Accuracy: {best_test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32fdc79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for A: 82.88 %\n",
      "Accuracy for B: 94.25 %\n",
      "Accuracy for C: 95.50 %\n",
      "Accuracy for D: 93.25 %\n",
      "Accuracy for E: 95.12 %\n",
      "Accuracy for F: 94.25 %\n",
      "Accuracy for G: 77.75 %\n",
      "Accuracy for H: 91.88 %\n",
      "Accuracy for I: 64.00 %\n",
      "Accuracy for J: 94.88 %\n",
      "Accuracy for K: 94.50 %\n",
      "Accuracy for L: 78.25 %\n",
      "Accuracy for M: 97.00 %\n",
      "Accuracy for N: 93.88 %\n",
      "Accuracy for O: 96.88 %\n",
      "Accuracy for P: 97.12 %\n",
      "Accuracy for Q: 82.88 %\n",
      "Accuracy for R: 94.88 %\n",
      "Accuracy for S: 97.75 %\n",
      "Accuracy for T: 97.25 %\n",
      "Accuracy for U: 89.12 %\n",
      "Accuracy for V: 94.88 %\n",
      "Accuracy for W: 96.12 %\n",
      "Accuracy for X: 95.50 %\n",
      "Accuracy for Y: 93.38 %\n",
      "Accuracy for Z: 97.88 %\n"
     ]
    }
   ],
   "source": [
    "class_accuracies=evaluate_per_class(model,test_dataloader,device)\n",
    "\n",
    "for letter, accuracy in class_accuracies.items():\n",
    "    print(f\"Accuracy for {letter}: {(accuracy*100):.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15j4i12v4gz",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# CNN Architecture matches model.py (nn.Sequential)\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),   # 0: 28x28 -> 28x28\n",
    "    nn.ReLU(),                         # 1\n",
    "    nn.MaxPool2d(2),                   # 2: 28x28 -> 14x14\n",
    "    nn.Conv2d(32, 64, 3, padding=1),  # 3: 14x14 -> 14x14\n",
    "    nn.ReLU(),                         # 4\n",
    "    nn.MaxPool2d(2),                   # 5: 14x14 -> 7x7\n",
    "    nn.Conv2d(64, 128, 3, padding=1), # 6: 7x7 -> 7x7\n",
    "    nn.ReLU(),                         # 7\n",
    "    nn.Flatten(),                      # 8: 128*7*7 = 6272\n",
    "    nn.Linear(6272, 256),             # 9\n",
    "    nn.ReLU(),                         # 10\n",
    "    nn.Dropout(0.5),                   # 11\n",
    "    nn.Linear(256, 26)                # 12\n",
    ")\n",
    "\n",
    "cnn_loss_function = nn.CrossEntropyLoss()\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "cnn_scheduler = optim.lr_scheduler.ReduceLROnPlateau(cnn_optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "print(f'CNN Model architecture:\\n{cnn_model}')\n",
    "print(f'Loss function: {cnn_loss_function}')\n",
    "print(f'Optimizer: {cnn_optimizer}')\n",
    "print(f'Scheduler: {cnn_scheduler}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4npu890b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.to(device)\n",
    "best_cnn_test_accuracy=0.0\n",
    "\n",
    "for epoch in range(30):\n",
    "    cnn_model.train()\n",
    "    running_loss=0.0\n",
    "    num_correct_predictions=0\n",
    "    total_predictions=0\n",
    "\n",
    "    for batch_num,(data,labels) in enumerate(train_dataloader):\n",
    "        data,labels=data.to(device),labels.to(device)\n",
    "        labels=labels-1\n",
    "\n",
    "        cnn_optimizer.zero_grad()\n",
    "        outputs=cnn_model(data)\n",
    "        loss=cnn_loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "        predicted_indices=torch.argmax(outputs,dim=1)\n",
    "        num_correct_predictions+=(predicted_indices==labels).sum().item()\n",
    "        total_predictions+=len(labels)\n",
    "\n",
    "    average_loss=running_loss/len(train_dataloader)\n",
    "    train_accuracy=(num_correct_predictions/total_predictions)*100\n",
    "    test_accuracy=evaluate(cnn_model,test_dataloader,device,verbose=False)\n",
    "    cnn_scheduler.step(test_accuracy)\n",
    "    current_lr=cnn_optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if test_accuracy>best_cnn_test_accuracy:\n",
    "        best_cnn_test_accuracy=test_accuracy\n",
    "        torch.save(cnn_model.state_dict(),'cnn_emnist.pth')\n",
    "        print(f\"Epoch {epoch+1}/30 | Train Loss: {average_loss:.4f} | Train Acc: {train_accuracy:.2f}% | Test Acc: {test_accuracy:.2f}% | LR: {current_lr:.6f} | *saved*\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}/30 | Train Loss: {average_loss:.4f} | Train Acc: {train_accuracy:.2f}% | Test Acc: {test_accuracy:.2f}% | LR: {current_lr:.6f}\")\n",
    "\n",
    "print(f\"\\nBest Test Accuracy: {best_cnn_test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e7e7174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for A: 97.88 %\n",
      "Accuracy for B: 98.00 %\n",
      "Accuracy for C: 98.00 %\n",
      "Accuracy for D: 96.38 %\n",
      "Accuracy for E: 98.88 %\n",
      "Accuracy for F: 97.25 %\n",
      "Accuracy for G: 84.62 %\n",
      "Accuracy for H: 96.12 %\n",
      "Accuracy for I: 76.88 %\n",
      "Accuracy for J: 95.62 %\n",
      "Accuracy for K: 98.88 %\n",
      "Accuracy for L: 76.50 %\n",
      "Accuracy for M: 99.50 %\n",
      "Accuracy for N: 97.50 %\n",
      "Accuracy for O: 98.00 %\n",
      "Accuracy for P: 99.00 %\n",
      "Accuracy for Q: 90.75 %\n",
      "Accuracy for R: 97.75 %\n",
      "Accuracy for S: 98.62 %\n",
      "Accuracy for T: 98.50 %\n",
      "Accuracy for U: 94.88 %\n",
      "Accuracy for V: 93.88 %\n",
      "Accuracy for W: 98.62 %\n",
      "Accuracy for X: 98.38 %\n",
      "Accuracy for Y: 97.12 %\n",
      "Accuracy for Z: 99.62 %\n"
     ]
    }
   ],
   "source": [
    "class_accuracies_cnn=evaluate_per_class(cnn_model,test_dataloader,device)\n",
    "for letter, accuracy in class_accuracies_cnn.items():\n",
    "    print(f\"Accuracy for {letter}: {(accuracy*100):.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
